{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 12:14:03.775886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:  ['.DS_Store', 'left hand', 'right hand']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708168453.692720       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-20.6.4), renderer: Intel(R) Iris(TM) Plus Graphics 645\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[0. 1.]] [0. 1.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0. 1.]] [0. 1.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[2.1900065e-16 1.0000000e+00]] [2.1900065e-16 1.0000000e+00]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[1. 0.]] [1. 0.]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[[0. 1.]] [0. 1.]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[8.266373e-19 1.000000e+00]] [8.266373e-19 1.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import optimizers  # Optimizer that we will use to train the model\n",
    "from tensorflow.keras.models import Sequential  # Allows us to make sequential neural networks\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D  # Layers for performing convolutions\n",
    "from tensorflow.keras import backend as K  # If there's a Keras session, we close it to keep everything clean\n",
    "\n",
    "model_path = '/Users/luna/Desktop/carpeta sin título/hand identifier/Model.h5'\n",
    "weights_path = '/Users/luna/Desktop/carpeta sin título/hand identifier/weights.h5'\n",
    "cnn = load_model(model_path)\n",
    "cnn.load_weights(weights_path)\n",
    "\n",
    "test_directory = '/Users/luna/Desktop/carpeta sin título/hand identifier/photos/test'\n",
    "test_images = os.listdir(test_directory)\n",
    "print(\"Names: \", test_images)\n",
    "\n",
    "# Reading the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------- Create an object that will store the detection and tracking of hands ------------\n",
    "hands_class = mp.solutions.hands\n",
    "hands = hands_class.Hands()\n",
    "\n",
    "drawing = mp.solutions.drawing_utils  # Draws the 21 key points of the hand\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    copy = frame.copy()\n",
    "    result = hands.process(color)\n",
    "    positions = []  # In this list, we will store the coordinates of the points\n",
    "    #print(result.multi_hand_landmarks)\n",
    "\n",
    "    if result.multi_hand_landmarks:  # If there is something in the results, we enter the if\n",
    "        for hand in result.multi_hand_landmarks:  # We look for the hand within the list of hands given by the descriptor\n",
    "            for id, lm in enumerate(hand.landmark):  # We will obtain the information of each hand found by the ID\n",
    "                height, width, c = frame.shape  # We extract the width and height of the frames to multiply them by the proportion\n",
    "                corx, cory = int(lm.x * width), int(lm.y * height)  # We extract the location of each point that belongs to the hand in coordinates\n",
    "                positions.append([id, corx, cory])\n",
    "                drawing.draw_landmarks(frame, hand, hands_class.HAND_CONNECTIONS)\n",
    "            if positions:\n",
    "                central_point = positions[9]\n",
    "                x1, y1 = (central_point[1] - 80), (central_point[2] - 80)\n",
    "                width, height = (x1 + 80), (y1 + 80)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                hand_region = copy[y1:y2, x1:x2]\n",
    "                hand_region = cv2.resize(hand_region, (200, 200), interpolation=cv2.INTER_CUBIC)  # Resize the photos\n",
    "                x = img_to_array(hand_region)  # Convert the image to an array\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                prediction = cnn.predict(x)  # It will be a 2-dimensional array, where it will put 1 in the class it believes correct\n",
    "                result = prediction[0]  # [1,0] | [0, 1]\n",
    "                response = np.argmax(result)  # It gives us the index of the highest value 0 | 1\n",
    "                if response == 1:\n",
    "                    print(prediction, result)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "                    cv2.putText(frame, '{}'.format(test_images[0]), (x1, y1 - 5), 1, 1.3, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                elif response == 0:\n",
    "                    print(prediction, result)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "                    cv2.putText(frame, '{}'.format(test_images[1]), (x1, y1 - 5), 1, 1.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (v3.11.5:cce6ba91b3, Aug 24 2023, 10:50:31) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
