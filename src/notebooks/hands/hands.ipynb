{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left hand | train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 11:22:34.998467: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created:  /Users/luna/Desktop/carpeta sin título/hand identifier/photos/train/left hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708165361.283278       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-20.6.4), renderer: Intel(R) Iris(TM) Plus Graphics 645\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp  # Hand detector (descriptor) library developed by Google\n",
    "import os\n",
    "\n",
    "#----------------------------- Create the folder where we will store the training data ---------------------------------\n",
    "name = 'left hand'\n",
    "path = '/Users/luna/Desktop/carpeta sin título/hand identifier/photos/train'\n",
    "folder = path + '/' + name\n",
    "if not os.path.exists(folder):\n",
    "    print('Folder created: ', folder)\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Assign a counter for the photo names\n",
    "count = 0\n",
    "\n",
    "# Read from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------- Create an object that will store the detection and tracking of hands ------------\n",
    "hands_class = mp.solutions.hands\n",
    "hands = hands_class.Hands()  # First parameter, FALSE so it doesn't detect 24/7\n",
    "                             # It will only detect when there is high confidence\n",
    "                             # Second parameter: maximum number of hands\n",
    "                             # Third parameter: minimum detection confidence\n",
    "                             # Fourth parameter: minimum tracking confidence\n",
    "\n",
    "#---------------------------------- Method to draw hands ---------------------------\n",
    "drawing = mp.solutions.drawing_utils  # With this method we draw 21 key points of the hand\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    copy = frame.copy()\n",
    "    result = hands.process(color)\n",
    "    positions = []  # In this list we will store the coordinates of the points\n",
    "    #print(result.multi_hand_landmarks) #If we want to see if there is detection\n",
    "\n",
    "    if result.multi_hand_landmarks:  # If there is something in the results we enter the if\n",
    "        for hand in result.multi_hand_landmarks:  # We look for the hand within the list of hands given by the descriptor\n",
    "            for id, lm in enumerate(hand.landmark):  # We will obtain the information of each hand found by the ID\n",
    "                #print(id,lm) #As they give us decimals (Image proportion) we must convert it to pixels\n",
    "                height, width, c = frame.shape  # We extract the width and height of the frames to multiply them by the proportion\n",
    "                corx, cory = int(lm.x*width), int(lm.y*height)  # We extract the location of each point that belongs to the hand in coordinates\n",
    "                positions.append([id, corx, cory])\n",
    "                drawing.draw_landmarks(frame, hand, hands_class.HAND_CONNECTIONS)\n",
    "            if positions:\n",
    "                central_point = positions[9]  # Central point\n",
    "                x1, y1 = (central_point[1]-80), (central_point[2]-80)  # We get the initial point and the lengths\n",
    "                width, height = (x1+80), (y1+80)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                hand_region = copy[y1:y2, x1:x2]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "            hand_region = cv2.resize(hand_region, (200, 200), interpolation=cv2.INTER_CUBIC)  # We resize the photos\n",
    "            cv2.imwrite(folder + \"/{}_hand.jpg\".format(count), hand_region)\n",
    "            count += 1\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27 or count >= 300:  # Exit on ESC key or after 300 images\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right hand | train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created:  /Users/luna/Desktop/carpeta sin título/hand identifier/photos/train/right hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708165449.875765       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-20.6.4), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp  # Hand detector (descriptor) library developed by Google\n",
    "import os\n",
    "\n",
    "#----------------------------- Create the folder where we will store the training data ---------------------------------\n",
    "name = 'right hand'\n",
    "path = '/Users/luna/Desktop/carpeta sin título/hand identifier/photos/train'\n",
    "folder = path + '/' + name\n",
    "if not os.path.exists(folder):\n",
    "    print('Folder created: ', folder)\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Assign a counter for the photo names\n",
    "count = 0\n",
    "\n",
    "# Read from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------- Create an object that will store the detection and tracking of hands ------------\n",
    "hands_class = mp.solutions.hands\n",
    "hands = hands_class.Hands()  # First parameter, FALSE so it doesn't detect 24/7\n",
    "                             # It will only detect when there is high confidence\n",
    "                             # Second parameter: maximum number of hands\n",
    "                             # Third parameter: minimum detection confidence\n",
    "                             # Fourth parameter: minimum tracking confidence\n",
    "\n",
    "#---------------------------------- Method to draw hands ---------------------------\n",
    "drawing = mp.solutions.drawing_utils  # With this method we draw 21 key points of the hand\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    copy = frame.copy()\n",
    "    result = hands.process(color)\n",
    "    positions = []  # In this list we will store the coordinates of the points\n",
    "    #print(result.multi_hand_landmarks) #If we want to see if there is detection\n",
    "\n",
    "    if result.multi_hand_landmarks:  # If there is something in the results we enter the if\n",
    "        for hand in result.multi_hand_landmarks:  # We look for the hand within the list of hands given by the descriptor\n",
    "            for id, lm in enumerate(hand.landmark):  # We will obtain the information of each hand found by the ID\n",
    "                #print(id,lm) #As they give us decimals (Image proportion) we must convert it to pixels\n",
    "                height, width, c = frame.shape  # We extract the width and height of the frames to multiply them by the proportion\n",
    "                corx, cory = int(lm.x*width), int(lm.y*height)  # We extract the location of each point that belongs to the hand in coordinates\n",
    "                positions.append([id, corx, cory])\n",
    "                drawing.draw_landmarks(frame, hand, hands_class.HAND_CONNECTIONS)\n",
    "            if positions:\n",
    "                central_point = positions[9]  # Central point\n",
    "                x1, y1 = (central_point[1]-80), (central_point[2]-80)  # We get the initial point and the lengths\n",
    "                width, height = (x1+80), (y1+80)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                hand_region = copy[y1:y2, x1:x2]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "            hand_region = cv2.resize(hand_region, (200, 200), interpolation=cv2.INTER_CUBIC)  # We resize the photos\n",
    "            cv2.imwrite(folder + \"/{}_hand.jpg\".format(count), hand_region)\n",
    "            count += 1\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27 or count >= 300:  # Exit on ESC key or after 300 images\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left hand | test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created:  /Users/luna/Desktop/carpeta sin título/hand identifier/photos/test/left hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708165406.769119       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-20.6.4), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp  # Hand detector (descriptor) library developed by Google\n",
    "import os\n",
    "\n",
    "#----------------------------- Create the folder where we will store the training data ---------------------------------\n",
    "name = 'left hand'\n",
    "path = '/Users/luna/Desktop/carpeta sin título/hand identifier/photos/test'\n",
    "folder = path + '/' + name\n",
    "if not os.path.exists(folder):\n",
    "    print('Folder created: ', folder)\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Assign a counter for the photo names\n",
    "count = 0\n",
    "\n",
    "# Read from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------- Create an object that will store the detection and tracking of hands ------------\n",
    "hands_class = mp.solutions.hands\n",
    "hands = hands_class.Hands()  # First parameter, FALSE so it doesn't detect 24/7\n",
    "                             # It will only detect when there is high confidence\n",
    "                             # Second parameter: maximum number of hands\n",
    "                             # Third parameter: minimum detection confidence\n",
    "                             # Fourth parameter: minimum tracking confidence\n",
    "\n",
    "#---------------------------------- Method to draw hands ---------------------------\n",
    "drawing = mp.solutions.drawing_utils  # With this method we draw 21 key points of the hand\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    copy = frame.copy()\n",
    "    result = hands.process(color)\n",
    "    positions = []  # In this list we will store the coordinates of the points\n",
    "    #print(result.multi_hand_landmarks) #If we want to see if there is detection\n",
    "\n",
    "    if result.multi_hand_landmarks:  # If there is something in the results we enter the if\n",
    "        for hand in result.multi_hand_landmarks:  # We look for the hand within the list of hands given by the descriptor\n",
    "            for id, lm in enumerate(hand.landmark):  # We will obtain the information of each hand found by the ID\n",
    "                #print(id,lm) #As they give us decimals (Image proportion) we must convert it to pixels\n",
    "                height, width, c = frame.shape  # We extract the width and height of the frames to multiply them by the proportion\n",
    "                corx, cory = int(lm.x*width), int(lm.y*height)  # We extract the location of each point that belongs to the hand in coordinates\n",
    "                positions.append([id, corx, cory])\n",
    "                drawing.draw_landmarks(frame, hand, hands_class.HAND_CONNECTIONS)\n",
    "            if positions:\n",
    "                central_point = positions[9]  # Central point\n",
    "                x1, y1 = (central_point[1]-80), (central_point[2]-80)  # We get the initial point and the lengths\n",
    "                width, height = (x1+80), (y1+80)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                hand_region = copy[y1:y2, x1:x2]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "            hand_region = cv2.resize(hand_region, (200, 200), interpolation=cv2.INTER_CUBIC)  # We resize the photos\n",
    "            cv2.imwrite(folder + \"/{}_hand.jpg\".format(count), hand_region)\n",
    "            count += 1\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27 or count >= 300:  # Exit on ESC key or after 300 images\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right hand | test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created:  /Users/luna/Desktop/carpeta sin título/hand identifier/photos/test/right hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1708165489.144879       1 gl_context.cc:344] GL version: 2.1 (2.1 INTEL-20.6.4), renderer: Intel(R) Iris(TM) Plus Graphics 645\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp  # Hand detector (descriptor) library developed by Google\n",
    "import os\n",
    "\n",
    "#----------------------------- Create the folder where we will store the training data ---------------------------------\n",
    "name = 'right hand'\n",
    "path = '/Users/luna/Desktop/carpeta sin título/hand identifier/photos/test'\n",
    "folder = path + '/' + name\n",
    "if not os.path.exists(folder):\n",
    "    print('Folder created: ', folder)\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Assign a counter for the photo names\n",
    "count = 0\n",
    "\n",
    "# Read from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#---------------------------- Create an object that will store the detection and tracking of hands ------------\n",
    "hands_class = mp.solutions.hands\n",
    "hands = hands_class.Hands()  # First parameter, FALSE so it doesn't detect 24/7\n",
    "                             # It will only detect when there is high confidence\n",
    "                             # Second parameter: maximum number of hands\n",
    "                             # Third parameter: minimum detection confidence\n",
    "                             # Fourth parameter: minimum tracking confidence\n",
    "\n",
    "#---------------------------------- Method to draw hands ---------------------------\n",
    "drawing = mp.solutions.drawing_utils  # With this method we draw 21 key points of the hand\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    copy = frame.copy()\n",
    "    result = hands.process(color)\n",
    "    positions = []  # In this list we will store the coordinates of the points\n",
    "    #print(result.multi_hand_landmarks) #If we want to see if there is detection\n",
    "\n",
    "    if result.multi_hand_landmarks:  # If there is something in the results we enter the if\n",
    "        for hand in result.multi_hand_landmarks:  # We look for the hand within the list of hands given by the descriptor\n",
    "            for id, lm in enumerate(hand.landmark):  # We will obtain the information of each hand found by the ID\n",
    "                #print(id,lm) #As they give us decimals (Image proportion) we must convert it to pixels\n",
    "                height, width, c = frame.shape  # We extract the width and height of the frames to multiply them by the proportion\n",
    "                corx, cory = int(lm.x*width), int(lm.y*height)  # We extract the location of each point that belongs to the hand in coordinates\n",
    "                positions.append([id, corx, cory])\n",
    "                drawing.draw_landmarks(frame, hand, hands_class.HAND_CONNECTIONS)\n",
    "            if positions:\n",
    "                central_point = positions[9]  # Central point\n",
    "                x1, y1 = (central_point[1]-80), (central_point[2]-80)  # We get the initial point and the lengths\n",
    "                width, height = (x1+80), (y1+80)\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                hand_region = copy[y1:y2, x1:x2]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "            hand_region = cv2.resize(hand_region, (200, 200), interpolation=cv2.INTER_CUBIC)  # We resize the photos\n",
    "            cv2.imwrite(folder + \"/{}_hand.jpg\".format(count), hand_region)\n",
    "            count += 1\n",
    "\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27 or count >= 300:  # Exit on ESC key or after 300 images\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (v3.11.5:cce6ba91b3, Aug 24 2023, 10:50:31) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
