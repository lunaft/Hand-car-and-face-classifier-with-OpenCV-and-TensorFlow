{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:53:33.557646: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "135/299 [============>.................] - ETA: 1:19 - loss: 0.0050 - accuracy: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5980.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "299/299 [==============================] - 67s 218ms/step - loss: 0.0050 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "training_data_path = '/Users/luna/Documents/Hand-car-and-face-classifier-with-OpenCV-and-TensorFlow/src/notebooks/hands/photos/train'\n",
    "validation_data_path = '/Users/luna/Documents/Hand-car-and-face-classifier-with-OpenCV-and-TensorFlow/src/notebooks/hands/photos/test'\n",
    "\n",
    "K.clear_session()  # Clear everything\n",
    "\n",
    "# Parameters\n",
    "iterations = 20  # Number of iterations to adjust our model\n",
    "height, width = 200, 200  # Size of the training images\n",
    "batch_size = 1  # Number of images that we will send sequentially\n",
    "steps = 299 / 1  # Number of times information will be processed in each iteration\n",
    "validation_steps = 299 / 1  # After each iteration, we validate the previous one\n",
    "conv1_filters = 32\n",
    "conv2_filters = 64  # Number of filters that we will apply in each convolution\n",
    "filter_size1 = (3, 3)\n",
    "filter_size2 = (2, 2)  # Sizes of filters 1 and 2\n",
    "pool_size = (2, 2)  # Size of the filter in max pooling\n",
    "classes = 2  # Open and closed hand (5 fingers and 0 fingers)\n",
    "lr = 0.0005  # Adjustments of the neural network to approach an optimal solution\n",
    "\n",
    "# Pre-Processing of the images\n",
    "training_preprocessing = ImageDataGenerator(\n",
    "    rescale=1. / 255,  # Scale pixels from 0 to 255 | 0 to 1\n",
    "    shear_range=0.3,  # Generate our images tilted for better training\n",
    "    zoom_range=0.3,  # Generates images with zoom for better training\n",
    "    horizontal_flip=True  # Flip the images for better training\n",
    ")\n",
    "\n",
    "validation_preprocessing = ImageDataGenerator(\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "training_image = training_preprocessing.flow_from_directory(\n",
    "    training_data_path,  # It will take the photos that we have already stored\n",
    "    target_size=(height, width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Categorical classification = by classes\n",
    ")\n",
    "\n",
    "validation_image = validation_preprocessing.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=(height, width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create the Convolutional Neural Network (CNN)\n",
    "cnn = Sequential()  # Sequential neural network\n",
    "# We add filters in order to make our image very deep but small\n",
    "cnn.add(Conv2D(conv1_filters, filter_size1, padding='same', input_shape=(height, width, 3), activation='relu'))  # Add the first layer\n",
    "cnn.add(MaxPooling2D(pool_size=pool_size))  # After the first layer, we will have a max pooling layer and assign the size\n",
    "\n",
    "cnn.add(Conv2D(conv2_filters, filter_size2, padding='same', activation='relu'))  # Add new layer\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Now we will convert that deep image into a flat one, to have 1 dimension with all the info\n",
    "cnn.add(Flatten())  # Flatten the image\n",
    "cnn.add(Dense(256, activation='relu'))  # Assign 256 neurons\n",
    "cnn.add(Dropout(0.5))  # Turn off 50% of the neurons in the previous function to avoid overfitting\n",
    "cnn.add(Dense(classes, activation='softmax'))  # It's our last layer, it tells us the probability of being one of the classes\n",
    "\n",
    "# Add parameters to optimize the model\n",
    "# During training have a self-evaluation, optimize with Adam, and the metric will be accuracy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# We will train our network\n",
    "cnn.fit(training_image, steps_per_epoch=steps, epochs=iterations, validation_data=validation_image, validation_steps=validation_steps)\n",
    "\n",
    "# Save the model\n",
    "cnn.save('Model.h5')\n",
    "cnn.save_weights('weights.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
